{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8177701,"sourceType":"datasetVersion","datasetId":4840814},{"sourceId":42514,"sourceType":"modelInstanceVersion","modelInstanceId":35723}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm\n!pip install peft\n!pip install einops\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom PIL import Image\nimport torchvision\nfrom torch import nn, optim\nimport timm\nimport imageio.v2 as imageio\nfrom torchvision.transforms import v2\nfrom glob import glob\nfrom sklearn.preprocessing import LabelEncoder\nimport time\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\nfrom torch import linalg as LA\nfrom einops import rearrange, repeat\nfrom einops.layers.torch import Rearrange","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-25T14:30:35.071625Z","iopub.execute_input":"2024-05-25T14:30:35.071989Z","iopub.status.idle":"2024-05-25T14:31:21.374583Z","shell.execute_reply.started":"2024-05-25T14:30:35.071959Z","shell.execute_reply":"2024-05-25T14:31:21.373643Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.22.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\nCollecting peft\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.29.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.11.1\nCollecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m727.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:16.128319Z","iopub.execute_input":"2024-05-25T14:32:16.128911Z","iopub.status.idle":"2024-05-25T14:32:16.132917Z","shell.execute_reply.started":"2024-05-25T14:32:16.128878Z","shell.execute_reply":"2024-05-25T14:32:16.132048Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"metadata = pd.read_csv('/kaggle/input/ham1000/dataverse_files — копия/HAM10000_metadata.csv')\nmetadata.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:20.527487Z","iopub.execute_input":"2024-05-25T14:32:20.528248Z","iopub.status.idle":"2024-05-25T14:32:20.591260Z","shell.execute_reply.started":"2024-05-25T14:32:20.528217Z","shell.execute_reply":"2024-05-25T14:32:20.590529Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"     lesion_id      image_id   dx dx_type   age   sex localization  \\\n0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n\n        dataset  \n0  vidir_modern  \n1  vidir_modern  \n2  vidir_modern  \n3  vidir_modern  \n4  vidir_modern  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lesion_id</th>\n      <th>image_id</th>\n      <th>dx</th>\n      <th>dx_type</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>localization</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HAM_0000118</td>\n      <td>ISIC_0027419</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n      <td>vidir_modern</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HAM_0000118</td>\n      <td>ISIC_0025030</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n      <td>vidir_modern</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HAM_0002730</td>\n      <td>ISIC_0026769</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n      <td>vidir_modern</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HAM_0002730</td>\n      <td>ISIC_0025661</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n      <td>vidir_modern</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HAM_0001466</td>\n      <td>ISIC_0031633</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>75.0</td>\n      <td>male</td>\n      <td>ear</td>\n      <td>vidir_modern</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"first_part = glob('/kaggle/input/ham1000/dataverse_files — копия/HAM10000_images_part_1/*')\nsecond_part = glob('/kaggle/input/ham1000/dataverse_files — копия/HAM10000_images_part_2/*')\nfirst_part.extend(second_part)\nfirst_part_id = [x.split('/')[-1].split('.')[0] for x in first_part]\n\ndf_paths = pd.DataFrame({'id': first_part_id, 'path': first_part})\ndf_paths.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:22.730494Z","iopub.execute_input":"2024-05-25T14:32:22.731317Z","iopub.status.idle":"2024-05-25T14:32:23.020641Z","shell.execute_reply.started":"2024-05-25T14:32:22.731287Z","shell.execute_reply":"2024-05-25T14:32:23.019736Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"             id                                               path\n0  ISIC_0028933  /kaggle/input/ham1000/dataverse_files — копия/...\n1  ISIC_0028394  /kaggle/input/ham1000/dataverse_files — копия/...\n2  ISIC_0027799  /kaggle/input/ham1000/dataverse_files — копия/...\n3  ISIC_0028100  /kaggle/input/ham1000/dataverse_files — копия/...\n4  ISIC_0027960  /kaggle/input/ham1000/dataverse_files — копия/...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0028933</td>\n      <td>/kaggle/input/ham1000/dataverse_files — копия/...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0028394</td>\n      <td>/kaggle/input/ham1000/dataverse_files — копия/...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0027799</td>\n      <td>/kaggle/input/ham1000/dataverse_files — копия/...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0028100</td>\n      <td>/kaggle/input/ham1000/dataverse_files — копия/...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0027960</td>\n      <td>/kaggle/input/ham1000/dataverse_files — копия/...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"metadata = metadata.merge(df_paths, left_on='image_id', right_on='id').drop(columns=['id'])","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:23.914481Z","iopub.execute_input":"2024-05-25T14:32:23.914940Z","iopub.status.idle":"2024-05-25T14:32:23.939091Z","shell.execute_reply.started":"2024-05-25T14:32:23.914909Z","shell.execute_reply":"2024-05-25T14:32:23.938168Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class ClassificationDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.data = dataframe.values\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, label = self.data[idx]\n        img = np.array(imageio.imread(img_path, pilmode='RGB'))\n        img = torchvision.transforms.ToTensor()(img)\n        #img = Image.open(img_path)\n        img = self.transform(img)\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:26.153822Z","iopub.execute_input":"2024-05-25T14:32:26.154186Z","iopub.status.idle":"2024-05-25T14:32:26.160740Z","shell.execute_reply.started":"2024-05-25T14:32:26.154159Z","shell.execute_reply":"2024-05-25T14:32:26.159758Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"transforms_train = v2.Compose([\n    v2.ToDtype(torch.float32, scale=True),\n    v2.Resize(size=(224, 224)),\n    v2.RandomRotation(15),\n    v2.RandomHorizontalFlip(p=0.5),\n    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n])\n\ntransforms_test = v2.Compose([\n    v2.ToDtype(torch.float32, scale=True),\n    v2.Resize(size=(224, 224)),\n    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:28.018601Z","iopub.execute_input":"2024-05-25T14:32:28.019319Z","iopub.status.idle":"2024-05-25T14:32:28.026400Z","shell.execute_reply.started":"2024-05-25T14:32:28.019287Z","shell.execute_reply":"2024-05-25T14:32:28.025329Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nmetadata['dx_encoded'] = le.fit_transform(metadata['dx'])","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:30.007641Z","iopub.execute_input":"2024-05-25T14:32:30.008499Z","iopub.status.idle":"2024-05-25T14:32:30.016333Z","shell.execute_reply.started":"2024-05-25T14:32:30.008467Z","shell.execute_reply":"2024-05-25T14:32:30.015369Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_idx, valid_idx = train_test_split(np.arange(metadata.shape[0]), test_size=0.3,\n                                            random_state=0)\ntrainset = ClassificationDataset(metadata.iloc[train_idx][['path', 'dx_encoded']],\n                                 transform=transforms_train)\nvalset = ClassificationDataset(metadata.iloc[valid_idx][['path', 'dx_encoded']],\n                               transform=transforms_test)\n\ndef collate_fn(data):\n    images, labels = zip(*data)\n    images = torch.stack(images)\n    labels = torch.tensor(labels)\n\n    return images.float(), labels.long()\n\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=32,\n                                           shuffle=True, num_workers=2, collate_fn = collate_fn)\nval_loader = torch.utils.data.DataLoader(valset, batch_size=32,\n                                         shuffle=False, num_workers=2, collate_fn = collate_fn)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:30.639263Z","iopub.execute_input":"2024-05-25T14:32:30.640073Z","iopub.status.idle":"2024-05-25T14:32:30.661430Z","shell.execute_reply.started":"2024-05-25T14:32:30.640035Z","shell.execute_reply":"2024-05-25T14:32:30.660520Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:32.491492Z","iopub.execute_input":"2024-05-25T14:32:32.491880Z","iopub.status.idle":"2024-05-25T14:32:32.543059Z","shell.execute_reply.started":"2024-05-25T14:32:32.491849Z","shell.execute_reply":"2024-05-25T14:32:32.542003Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ResNet","metadata":{}},{"cell_type":"code","source":"model = timm.create_model('resnet50', pretrained=True)\nnum_classes = 7\n\nnum_features = model.fc.in_features\n\nmodel.fc = nn.Sequential(\n    nn.Linear(num_features, num_classes)\n)\nmodel=model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:33.911456Z","iopub.execute_input":"2024-05-25T14:32:33.912135Z","iopub.status.idle":"2024-05-25T14:32:35.719740Z","shell.execute_reply.started":"2024-05-25T14:32:33.912103Z","shell.execute_reply":"2024-05-25T14:32:35.718747Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50ee7e643c2f404390b4d12f548fdc43"}},"metadata":{}}]},{"cell_type":"code","source":"def test(model, loader):\n    loss_log = []\n    acc_log = []\n    model.eval()\n\n    for data, target in loader:\n        data = data.to(device)\n        target = target.to(device)\n\n        with torch.no_grad():\n            predictions = model(data)\n            loss = nn.functional.cross_entropy(predictions, target)\n\n            loss_log.append(loss.item())\n\n            acc = sum(torch.argmax(predictions.cpu(), dim=1) ==\n                   target.cpu()) / target.cpu().shape[0]\n\n            acc_log.append(acc.item())\n\n    return np.mean(loss_log), np.mean(acc_log)\n\ndef train_epoch(model, optimizer, train_loader):\n    loss_log = []\n    acc_log = []\n    model.train()\n\n    for data, target in train_loader:\n        data = data.to(device)\n        target = target.to(device)\n\n        optimizer.zero_grad()\n        predictions = model(data)\n        loss = nn.functional.cross_entropy(predictions, target)\n        loss.backward()\n        optimizer.step()\n\n        loss_log.append(loss.item())\n\n        with torch.no_grad():\n            acc = sum(torch.argmax(predictions.cpu(), dim=1) ==\n                   target.cpu()) / target.cpu().shape[0]\n\n        acc_log.append(acc.item())\n\n    return loss_log, acc_log\n\ndef train(model, optimizer, n_epochs, train_loader, val_loader, scheduler=None):\n    train_loss_log, train_acc_log, val_loss_log, val_acc_log = [], [], [], []\n\n    for epoch in range(n_epochs):\n        train_loss, train_acc = train_epoch(model, optimizer, train_loader)\n        val_loss, val_acc = test(model, val_loader)\n\n        train_loss_log.extend(train_loss)\n        train_acc_log.extend(train_acc)\n\n        val_loss_log.append(val_loss)\n        val_acc_log.append(val_acc)\n\n        print(f\"Epoch {epoch}\")\n        print(f\" train loss: {np.mean(train_loss)}, train acc: {np.mean(train_acc)}\")\n        print(f\" val loss: {val_loss}, val acc: {val_acc}\\n\")\n\n        if scheduler is not None:\n            scheduler.step(val_acc)\n\n    return train_loss_log, train_acc_log, val_loss_log, val_acc_log","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:36.621606Z","iopub.execute_input":"2024-05-25T14:32:36.622289Z","iopub.status.idle":"2024-05-25T14:32:36.636193Z","shell.execute_reply.started":"2024-05-25T14:32:36.622257Z","shell.execute_reply":"2024-05-25T14:32:36.635197Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())\ntrain_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer,\n                                                                 10, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:38.602898Z","iopub.execute_input":"2024-05-25T14:32:38.603261Z","iopub.status.idle":"2024-05-25T14:48:33.038975Z","shell.execute_reply.started":"2024-05-25T14:32:38.603230Z","shell.execute_reply":"2024-05-25T14:48:33.037719Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 0\n train loss: 0.7865359099073843, train acc: 0.7244318181818182\n val loss: 0.6595055194611245, val acc: 0.7736954327593458\n\nEpoch 1\n train loss: 0.5698627220636064, train acc: 0.79375\n val loss: 0.6670140148477351, val acc: 0.7720331987167927\n\nEpoch 2\n train loss: 0.49801584807309235, train acc: 0.8188920454545454\n val loss: 0.5821532759260624, val acc: 0.7914526779600914\n\nEpoch 3\n train loss: 0.4089071396399628, train acc: 0.8509943181818181\n val loss: 0.639537106486077, val acc: 0.7947771460451978\n\nEpoch 4\n train loss: 0.3513155439021913, train acc: 0.8731534090909091\n val loss: 0.49643905968108076, val acc: 0.8280218268962617\n\nEpoch 5\n train loss: 0.31235405636781993, train acc: 0.8849431818181818\n val loss: 0.4509113091737666, val acc: 0.8376627843430702\n\nEpoch 6\n train loss: 0.28685720872811293, train acc: 0.8931818181818182\n val loss: 0.5369006913710148, val acc: 0.821304108868254\n\nEpoch 7\n train loss: 0.23501634642651134, train acc: 0.9105113636363636\n val loss: 0.6593333008758565, val acc: 0.8119955982299562\n\nEpoch 8\n train loss: 0.21143713856793261, train acc: 0.9220170454545454\n val loss: 0.4961439337026566, val acc: 0.8406891968656094\n\nEpoch 9\n train loss: 0.1659090518697419, train acc: 0.9382102272727273\n val loss: 0.9059902285324767, val acc: 0.7680438370146649\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import timeit\npreds = []\ngt = []\n\nloss_log = []\nacc_log = []\nmodel.eval()\n    \nstartT = timeit.default_timer() \nfor data, target in val_loader:\n    data = data.to(device)\n    target = target.to(device)\n\n    with torch.no_grad():\n        predictions = model(data)\n        loss = nn.functional.cross_entropy(predictions, target)\n\n        loss_log.append(loss.item())\n\n        acc = sum(torch.argmax(predictions.cpu(), dim=1) ==\n                target.cpu()) / target.cpu().shape[0]\n\n        acc_log.append(acc.item())\n        \n        for i in range(len(target)):\n            preds.append(torch.argmax(predictions[i].cpu()))\n            gt.append(target[i].cpu())\n            \nendT = timeit.default_timer()\nrun_time = endT-startT","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:49:13.318220Z","iopub.execute_input":"2024-05-25T14:49:13.318590Z","iopub.status.idle":"2024-05-25T14:49:35.738445Z","shell.execute_reply.started":"2024-05-25T14:49:13.318558Z","shell.execute_reply":"2024-05-25T14:49:35.737383Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(np.squeeze(gt), np.squeeze(preds)))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:50:13.951622Z","iopub.execute_input":"2024-05-25T14:50:13.952018Z","iopub.status.idle":"2024-05-25T14:50:14.009966Z","shell.execute_reply.started":"2024-05-25T14:50:13.951984Z","shell.execute_reply":"2024-05-25T14:50:14.009039Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.58      0.52      0.55        93\n           1       0.86      0.29      0.44       164\n           2       0.39      0.93      0.54       315\n           3       0.95      0.41      0.57        44\n           4       0.62      0.36      0.46       338\n           5       0.94      0.87      0.90      2012\n           6       0.85      0.90      0.88        39\n\n    accuracy                           0.77      3005\n   macro avg       0.74      0.61      0.62      3005\nweighted avg       0.83      0.77      0.77      3005\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ViT base","metadata":{}},{"cell_type":"code","source":"model = timm.create_model('vit_base_patch16_224.augreg2_in21k_ft_in1k', pretrained=True)\nnum_classes = 7\n\nnum_features = model.head.in_features\n\nmodel.head = nn.Sequential(\n    nn.Linear(num_features, num_classes)\n)\nmodel=model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:51:06.561529Z","iopub.execute_input":"2024-05-25T14:51:06.562402Z","iopub.status.idle":"2024-05-25T14:51:10.491505Z","shell.execute_reply.started":"2024-05-25T14:51:06.562367Z","shell.execute_reply":"2024-05-25T14:51:10.490722Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cd283089df54d13a04fd8508047aa7c"}},"metadata":{}}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())\ntrain_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer,\n                                                                 10, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:51:14.850152Z","iopub.execute_input":"2024-05-25T14:51:14.850511Z","iopub.status.idle":"2024-05-25T15:35:07.073958Z","shell.execute_reply.started":"2024-05-25T14:51:14.850482Z","shell.execute_reply":"2024-05-25T15:35:07.072731Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 0\n train loss: 1.2448290841145948, train acc: 0.6475852272727273\n val loss: 1.028932271802679, val acc: 0.6675761189866574\n\nEpoch 1\n train loss: 0.9554861247034172, train acc: 0.665625\n val loss: 1.0812673841385132, val acc: 0.6695364085917778\n\nEpoch 2\n train loss: 0.9119417255575006, train acc: 0.6764204545454545\n val loss: 1.049151655841381, val acc: 0.6459326851875224\n\nEpoch 3\n train loss: 0.8845450619404966, train acc: 0.6818181818181818\n val loss: 0.9836938825059445, val acc: 0.6579007702939054\n\nEpoch 4\n train loss: 0.8490247857841579, train acc: 0.6931818181818182\n val loss: 0.969762884555979, val acc: 0.6729640497806224\n\nEpoch 5\n train loss: 0.8363007584756071, train acc: 0.6936079545454545\n val loss: 0.8424312795730348, val acc: 0.6819401136104096\n\nEpoch 6\n train loss: 0.8334008894183419, train acc: 0.6927556818181818\n val loss: 0.8861818047280007, val acc: 0.6792461478963812\n\nEpoch 7\n train loss: 0.8423483331095089, train acc: 0.6896306818181818\n val loss: 0.9581514463779774, val acc: 0.6729640497806224\n\nEpoch 8\n train loss: 0.8970950558781624, train acc: 0.6788352272727273\n val loss: 0.905248134060109, val acc: 0.6768846296249552\n\nEpoch 9\n train loss: 0.8855649921027097, train acc: 0.6850852272727272\n val loss: 0.9372161116371763, val acc: 0.6616264670453174\n\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = []\ngt = []\n\nloss_log = []\nacc_log = []\nmodel.eval()\n    \nstartT = timeit.default_timer() \nfor data, target in val_loader:\n    data = data.to(device)\n    target = target.to(device)\n\n    with torch.no_grad():\n        predictions = model(data)\n        loss = nn.functional.cross_entropy(predictions, target)\n\n        loss_log.append(loss.item())\n\n        acc = sum(torch.argmax(predictions.cpu(), dim=1) ==\n                target.cpu()) / target.cpu().shape[0]\n\n        acc_log.append(acc.item())\n        \n        for i in range(len(target)):\n            preds.append(torch.argmax(predictions[i].cpu()))\n            gt.append(target[i].cpu())\n            \nendT = timeit.default_timer()\nrun_time = endT-startT","metadata":{"execution":{"iopub.status.busy":"2024-05-25T15:41:15.027681Z","iopub.execute_input":"2024-05-25T15:41:15.028730Z","iopub.status.idle":"2024-05-25T15:41:49.149697Z","shell.execute_reply.started":"2024-05-25T15:41:15.028674Z","shell.execute_reply":"2024-05-25T15:41:49.148623Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(classification_report(np.squeeze(gt), np.squeeze(preds)))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T15:41:49.151398Z","iopub.execute_input":"2024-05-25T15:41:49.151737Z","iopub.status.idle":"2024-05-25T15:41:49.207683Z","shell.execute_reply.started":"2024-05-25T15:41:49.151702Z","shell.execute_reply":"2024-05-25T15:41:49.206703Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.19      0.10      0.13        93\n           1       0.50      0.03      0.06       164\n           2       0.34      0.05      0.09       315\n           3       0.00      0.00      0.00        44\n           4       0.24      0.27      0.25       338\n           5       0.74      0.92      0.82      2012\n           6       0.40      0.26      0.31        39\n\n    accuracy                           0.66      3005\n   macro avg       0.35      0.23      0.24      3005\nweighted avg       0.60      0.66      0.60      3005\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Base dinov2","metadata":{}},{"cell_type":"code","source":"model = timm.create_model('vit_base_patch14_dinov2.lvd142m', pretrained=True)\nmodel.eval()\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T15:44:55.415090Z","iopub.execute_input":"2024-05-25T15:44:55.415859Z","iopub.status.idle":"2024-05-25T15:44:59.326791Z","shell.execute_reply.started":"2024-05-25T15:44:55.415825Z","shell.execute_reply":"2024-05-25T15:44:59.325817Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e720e9b4034f4dadb8a2ba26c5367b57"}},"metadata":{}}]},{"cell_type":"code","source":"trainset = ClassificationDataset(metadata.iloc[train_idx][['path', 'dx_encoded']],\n                                 transform=transforms_train)\nvalset = ClassificationDataset(metadata.iloc[valid_idx][['path', 'dx_encoded']],\n                               transform=transforms_test)\n\ntransforms_train = v2.Compose([\n    v2.ToDtype(torch.float32, scale=True),\n    v2.Resize(size=(518, 518)),\n    v2.RandomRotation(15),\n    v2.RandomHorizontalFlip(p=0.5),\n    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n])\n\ntransforms_test = v2.Compose([\n    v2.ToDtype(torch.float32, scale=True),\n    v2.Resize(size=(518, 518)),\n    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n])\n\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=32,\n                                           shuffle=True, num_workers=2, collate_fn = collate_fn)\nval_loader = torch.utils.data.DataLoader(valset, batch_size=32,\n                                         shuffle=False, num_workers=2, collate_fn = collate_fn)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:36:50.743076Z","iopub.execute_input":"2024-05-25T16:36:50.743505Z","iopub.status.idle":"2024-05-25T16:36:50.768985Z","shell.execute_reply.started":"2024-05-25T16:36:50.743468Z","shell.execute_reply":"2024-05-25T16:36:50.768157Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nembeddings = []\nlabels = []\nfor i in tqdm(range(len(trainset))):\n    data, label = trainset[i]\n    embeddings.append(model(data.unsqueeze(0).to(device)).cpu().detach().numpy())\n    labels.append(label)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T15:52:59.950511Z","iopub.execute_input":"2024-05-25T15:52:59.951298Z","iopub.status.idle":"2024-05-25T16:06:06.221583Z","shell.execute_reply.started":"2024-05-25T15:52:59.951265Z","shell.execute_reply":"2024-05-25T16:06:06.220482Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7010 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a78b72e9c444f1aa8bece5c0fc4e1d2"}},"metadata":{}}]},{"cell_type":"code","source":"np.squeeze(np.array(embeddings), 1).shape","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:11:55.635062Z","iopub.execute_input":"2024-05-25T16:11:55.635319Z","iopub.status.idle":"2024-05-25T16:11:55.651765Z","shell.execute_reply.started":"2024-05-25T16:11:55.635297Z","shell.execute_reply":"2024-05-25T16:11:55.650925Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(7010, 768)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import svm\n\nclf = svm.SVC(gamma='scale')\n\nclf.fit(np.squeeze(np.array(embeddings), 1), labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:11:55.652882Z","iopub.execute_input":"2024-05-25T16:11:55.653146Z","iopub.status.idle":"2024-05-25T16:12:05.256861Z","shell.execute_reply.started":"2024-05-25T16:11:55.653124Z","shell.execute_reply":"2024-05-25T16:12:05.255931Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"SVC()","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"predictions = clf.predict(np.squeeze(np.array(embeddings), 1))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:12:05.258058Z","iopub.execute_input":"2024-05-25T16:12:05.258408Z","iopub.status.idle":"2024-05-25T16:12:19.653760Z","shell.execute_reply.started":"2024-05-25T16:12:05.258375Z","shell.execute_reply":"2024-05-25T16:12:19.652922Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"sum(predictions==np.array(labels))/predictions.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:12:19.654842Z","iopub.execute_input":"2024-05-25T16:12:19.655137Z","iopub.status.idle":"2024-05-25T16:12:19.663536Z","shell.execute_reply.started":"2024-05-25T16:12:19.655113Z","shell.execute_reply":"2024-05-25T16:12:19.662660Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0.8492154065620542"},"metadata":{}}]},{"cell_type":"code","source":"embeddings_test = []\nlabels_test = []\nfor i in tqdm(range(len(valset))):\n    data, label = valset[i]\n    embeddings_test.append(model(data.unsqueeze(0).to(device)).cpu().detach().numpy())\n    labels_test.append(label)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:12:19.664632Z","iopub.execute_input":"2024-05-25T16:12:19.664929Z","iopub.status.idle":"2024-05-25T16:17:33.212408Z","shell.execute_reply.started":"2024-05-25T16:12:19.664906Z","shell.execute_reply":"2024-05-25T16:17:33.211445Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3005 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62b375cc054a42c3ac1a82951236d80c"}},"metadata":{}}]},{"cell_type":"code","source":"predictions_test = clf.predict(np.squeeze(np.array(embeddings_test), 1))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:17:33.213797Z","iopub.execute_input":"2024-05-25T16:17:33.214136Z","iopub.status.idle":"2024-05-25T16:17:39.958094Z","shell.execute_reply.started":"2024-05-25T16:17:33.214111Z","shell.execute_reply":"2024-05-25T16:17:39.957200Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"sum(predictions_test==np.array(labels_test))/predictions_test.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:17:39.959166Z","iopub.execute_input":"2024-05-25T16:17:39.959447Z","iopub.status.idle":"2024-05-25T16:17:39.966650Z","shell.execute_reply.started":"2024-05-25T16:17:39.959423Z","shell.execute_reply":"2024-05-25T16:17:39.965803Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"0.8076539101497504"},"metadata":{}}]},{"cell_type":"code","source":"print(classification_report(np.array(labels_test), predictions_test))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:23:25.569950Z","iopub.execute_input":"2024-05-25T16:23:25.570873Z","iopub.status.idle":"2024-05-25T16:23:25.588580Z","shell.execute_reply.started":"2024-05-25T16:23:25.570839Z","shell.execute_reply":"2024-05-25T16:23:25.587742Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.58      0.15      0.24        93\n           1       0.72      0.68      0.70       164\n           2       0.59      0.68      0.63       315\n           3       1.00      0.05      0.09        44\n           4       0.58      0.37      0.45       338\n           5       0.87      0.96      0.92      2012\n           6       0.95      0.46      0.62        39\n\n    accuracy                           0.81      3005\n   macro avg       0.76      0.48      0.52      3005\nweighted avg       0.80      0.81      0.79      3005\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Large dinov2","metadata":{}},{"cell_type":"code","source":"model = timm.create_model('vit_large_patch14_dinov2.lvd142m', pretrained=True)\nmodel.eval()\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:23:38.262036Z","iopub.execute_input":"2024-05-25T16:23:38.262951Z","iopub.status.idle":"2024-05-25T16:24:19.584524Z","shell.execute_reply.started":"2024-05-25T16:23:38.262918Z","shell.execute_reply":"2024-05-25T16:24:19.583752Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20f11a7945d8444ca014a264787e1d73"}},"metadata":{}}]},{"cell_type":"code","source":"data_config = timm.data.resolve_model_data_config(model)\ntransforms_dino = timm.data.create_transform(**data_config, is_training=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:34:58.298050Z","iopub.execute_input":"2024-05-25T16:34:58.298432Z","iopub.status.idle":"2024-05-25T16:34:58.303897Z","shell.execute_reply.started":"2024-05-25T16:34:58.298404Z","shell.execute_reply":"2024-05-25T16:34:58.302822Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nembeddings = []\nlabels = []\n\n#trainset_dino = ClassificationDataset(metadata.iloc[train_idx][['path', 'dx_encoded']],\n#                                 transform=transforms_dino)\n#train_loader_dino = torch.utils.data.DataLoader(trainset_dino, batch_size=32,shuffle=False,\n#                                           collate_fn = collate_fn, num_workers=2)\n\nfor data, target in tqdm(train_loader):\n    data = data.to(device)\n\n    with torch.no_grad():\n        embeddings.extend(model(data).cpu().numpy())\n        \n    labels.extend(target)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:37:04.670905Z","iopub.execute_input":"2024-05-25T16:37:04.671589Z","iopub.status.idle":"2024-05-25T17:11:44.830079Z","shell.execute_reply.started":"2024-05-25T16:37:04.671556Z","shell.execute_reply":"2024-05-25T17:11:44.829028Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af2490534304f81ae0a4f97391a9ea8"}},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import svm\n\nclf = svm.SVC(gamma='scale')\n\nclf.fit(np.array(embeddings), labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:17:19.106529Z","iopub.execute_input":"2024-05-25T17:17:19.107029Z","iopub.status.idle":"2024-05-25T17:17:33.959943Z","shell.execute_reply.started":"2024-05-25T17:17:19.106991Z","shell.execute_reply":"2024-05-25T17:17:33.959007Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"SVC()","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"predictions = clf.predict(np.array(embeddings))\nsum(predictions==np.array(labels))/predictions.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:17:37.770797Z","iopub.execute_input":"2024-05-25T17:17:37.771558Z","iopub.status.idle":"2024-05-25T17:17:56.499103Z","shell.execute_reply.started":"2024-05-25T17:17:37.771526Z","shell.execute_reply":"2024-05-25T17:17:56.498142Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"0.8584878744650499"},"metadata":{}}]},{"cell_type":"code","source":"embeddings_val = []\nlabels_val = []\n\nfor data, target in tqdm(val_loader):\n    data = data.to(device)\n\n    with torch.no_grad():\n        embeddings_val.extend(model(data).cpu().numpy())\n        \n    labels_val.extend(target)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:19:25.019642Z","iopub.execute_input":"2024-05-25T17:19:25.020513Z","iopub.status.idle":"2024-05-25T17:34:17.797179Z","shell.execute_reply.started":"2024-05-25T17:19:25.020482Z","shell.execute_reply":"2024-05-25T17:34:17.795988Z"},"trusted":true},"execution_count":51,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51d7f4c953764d0f8d1620c1aa2d2f46"}},"metadata":{}}]},{"cell_type":"code","source":"predictions = np.squeeze(clf.predict(np.array(embeddings_val)))\nsum(predictions==np.array(labels_val))/predictions.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:42:37.353357Z","iopub.execute_input":"2024-05-25T17:42:37.353792Z","iopub.status.idle":"2024-05-25T17:42:44.971283Z","shell.execute_reply.started":"2024-05-25T17:42:37.353761Z","shell.execute_reply":"2024-05-25T17:42:44.970522Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"0.8149750415973378"},"metadata":{}}]},{"cell_type":"code","source":"print(classification_report(np.array(labels_val), predictions))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:42:44.972748Z","iopub.execute_input":"2024-05-25T17:42:44.973046Z","iopub.status.idle":"2024-05-25T17:42:45.007231Z","shell.execute_reply.started":"2024-05-25T17:42:44.973022Z","shell.execute_reply":"2024-05-25T17:42:45.006343Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.61      0.30      0.40        93\n           1       0.72      0.70      0.71       164\n           2       0.60      0.69      0.64       315\n           3       1.00      0.02      0.04        44\n           4       0.64      0.39      0.49       338\n           5       0.88      0.96      0.92      2012\n           6       0.96      0.59      0.73        39\n\n    accuracy                           0.81      3005\n   macro avg       0.77      0.52      0.56      3005\nweighted avg       0.81      0.81      0.80      3005\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Swinv2","metadata":{}},{"cell_type":"code","source":"model = timm.create_model('swinv2_base_window8_256.ms_in1k', pretrained=True)\nmodel.eval()\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:42:51.480221Z","iopub.execute_input":"2024-05-25T17:42:51.481472Z","iopub.status.idle":"2024-05-25T17:43:00.178985Z","shell.execute_reply.started":"2024-05-25T17:42:51.481400Z","shell.execute_reply":"2024-05-25T17:43:00.178201Z"},"trusted":true},"execution_count":55,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/354M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cb979d3522649849b927348bc0233ec"}},"metadata":{}}]},{"cell_type":"code","source":"transforms_256 = v2.Compose([\n    v2.ToDtype(torch.float32, scale=True),\n    v2.Resize(size=(256, 256)),\n    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n])\ntrainset_256 = ClassificationDataset(metadata.iloc[train_idx][['path', 'dx_encoded']],\n                                 transform=transforms_256)\nvalset_256 = ClassificationDataset(metadata.iloc[valid_idx][['path', 'dx_encoded']],\n                                 transform=transforms_256)\ntrain_loader_256 = torch.utils.data.DataLoader(trainset_256, batch_size=64,\n                                                      shuffle=False,\n                                           collate_fn = collate_fn)\nval_loader_256 = torch.utils.data.DataLoader(valset_256, batch_size=64,\n                                         shuffle=False, collate_fn = collate_fn)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:43:23.762589Z","iopub.execute_input":"2024-05-25T17:43:23.763294Z","iopub.status.idle":"2024-05-25T17:43:23.781668Z","shell.execute_reply.started":"2024-05-25T17:43:23.763260Z","shell.execute_reply":"2024-05-25T17:43:23.780827Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nembeddings = []\nlabels = []\n\nfor data, target in tqdm(train_loader_256):\n    data = data.to(device)\n\n    with torch.no_grad():\n        embeddings.extend(model(data).cpu().numpy())\n        \n    labels.extend(target)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:43:28.894743Z","iopub.execute_input":"2024-05-25T17:43:28.895407Z","iopub.status.idle":"2024-05-25T17:46:42.345676Z","shell.execute_reply.started":"2024-05-25T17:43:28.895375Z","shell.execute_reply":"2024-05-25T17:46:42.344760Z"},"trusted":true},"execution_count":57,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce9c9a5dc8f646ac93db742c3167456f"}},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import svm\n\nclf = svm.SVC(gamma='scale')\n\nclf.fit(np.array(embeddings), labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:46:42.347290Z","iopub.execute_input":"2024-05-25T17:46:42.347579Z","iopub.status.idle":"2024-05-25T17:46:59.653074Z","shell.execute_reply.started":"2024-05-25T17:46:42.347553Z","shell.execute_reply":"2024-05-25T17:46:59.652116Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"SVC()","text/html":"<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"predictions = clf.predict(np.array(embeddings))\nsum(predictions==np.array(labels))/predictions.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:46:59.654265Z","iopub.execute_input":"2024-05-25T17:46:59.654555Z","iopub.status.idle":"2024-05-25T17:47:19.943555Z","shell.execute_reply.started":"2024-05-25T17:46:59.654531Z","shell.execute_reply":"2024-05-25T17:47:19.942609Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"0.8114122681883025"},"metadata":{}}]},{"cell_type":"code","source":"embeddings_val = []\nlabels_val = []\n\nfor data, target in tqdm(val_loader_256):\n    data = data.to(device)\n\n    with torch.no_grad():\n        embeddings_val.extend(model(data).cpu().numpy())\n        \n    labels_val.extend(target)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:47:19.945402Z","iopub.execute_input":"2024-05-25T17:47:19.945724Z","iopub.status.idle":"2024-05-25T17:48:43.636664Z","shell.execute_reply.started":"2024-05-25T17:47:19.945675Z","shell.execute_reply":"2024-05-25T17:48:43.635826Z"},"trusted":true},"execution_count":60,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/47 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b884082c73a443f803948aeed8018a9"}},"metadata":{}}]},{"cell_type":"code","source":"predictions = np.squeeze(clf.predict(np.array(embeddings_val)))\nsum(predictions==np.array(labels_val))/predictions.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:48:43.637801Z","iopub.execute_input":"2024-05-25T17:48:43.638091Z","iopub.status.idle":"2024-05-25T17:48:52.367459Z","shell.execute_reply.started":"2024-05-25T17:48:43.638067Z","shell.execute_reply":"2024-05-25T17:48:52.366546Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"0.762063227953411"},"metadata":{}}]},{"cell_type":"code","source":"print(classification_report(np.array(labels_val), predictions))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:57:17.936518Z","iopub.execute_input":"2024-05-25T17:57:17.937363Z","iopub.status.idle":"2024-05-25T17:57:17.972498Z","shell.execute_reply.started":"2024-05-25T17:57:17.937328Z","shell.execute_reply":"2024-05-25T17:57:17.971681Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.59      0.29      0.39        93\n           1       0.63      0.35      0.45       164\n           2       0.55      0.50      0.52       315\n           3       1.00      0.02      0.04        44\n           4       0.66      0.23      0.34       338\n           5       0.80      0.97      0.88      2012\n           6       1.00      0.21      0.34        39\n\n    accuracy                           0.76      3005\n   macro avg       0.75      0.37      0.42      3005\nweighted avg       0.75      0.76      0.72      3005\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Base dinov2 + linear layer and peft training","metadata":{}},{"cell_type":"code","source":"model = timm.create_model('vit_base_patch14_dinov2.lvd142m', pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False\n    \nnum_classes = 7\n\nnum_features = 768\n\nmodel.head = nn.Sequential(\n    nn.Linear(num_features, num_classes)\n)\nmodel=model.to(device)    \n\nfor name, param in model.named_parameters():\n    print(name,param.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:57:46.731349Z","iopub.execute_input":"2024-05-25T17:57:46.731822Z","iopub.status.idle":"2024-05-25T17:57:48.607378Z","shell.execute_reply.started":"2024-05-25T17:57:46.731784Z","shell.execute_reply":"2024-05-25T17:57:48.606528Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"cls_token False\npos_embed False\npatch_embed.proj.weight False\npatch_embed.proj.bias False\nblocks.0.norm1.weight False\nblocks.0.norm1.bias False\nblocks.0.attn.qkv.weight False\nblocks.0.attn.qkv.bias False\nblocks.0.attn.proj.weight False\nblocks.0.attn.proj.bias False\nblocks.0.ls1.gamma False\nblocks.0.norm2.weight False\nblocks.0.norm2.bias False\nblocks.0.mlp.fc1.weight False\nblocks.0.mlp.fc1.bias False\nblocks.0.mlp.fc2.weight False\nblocks.0.mlp.fc2.bias False\nblocks.0.ls2.gamma False\nblocks.1.norm1.weight False\nblocks.1.norm1.bias False\nblocks.1.attn.qkv.weight False\nblocks.1.attn.qkv.bias False\nblocks.1.attn.proj.weight False\nblocks.1.attn.proj.bias False\nblocks.1.ls1.gamma False\nblocks.1.norm2.weight False\nblocks.1.norm2.bias False\nblocks.1.mlp.fc1.weight False\nblocks.1.mlp.fc1.bias False\nblocks.1.mlp.fc2.weight False\nblocks.1.mlp.fc2.bias False\nblocks.1.ls2.gamma False\nblocks.2.norm1.weight False\nblocks.2.norm1.bias False\nblocks.2.attn.qkv.weight False\nblocks.2.attn.qkv.bias False\nblocks.2.attn.proj.weight False\nblocks.2.attn.proj.bias False\nblocks.2.ls1.gamma False\nblocks.2.norm2.weight False\nblocks.2.norm2.bias False\nblocks.2.mlp.fc1.weight False\nblocks.2.mlp.fc1.bias False\nblocks.2.mlp.fc2.weight False\nblocks.2.mlp.fc2.bias False\nblocks.2.ls2.gamma False\nblocks.3.norm1.weight False\nblocks.3.norm1.bias False\nblocks.3.attn.qkv.weight False\nblocks.3.attn.qkv.bias False\nblocks.3.attn.proj.weight False\nblocks.3.attn.proj.bias False\nblocks.3.ls1.gamma False\nblocks.3.norm2.weight False\nblocks.3.norm2.bias False\nblocks.3.mlp.fc1.weight False\nblocks.3.mlp.fc1.bias False\nblocks.3.mlp.fc2.weight False\nblocks.3.mlp.fc2.bias False\nblocks.3.ls2.gamma False\nblocks.4.norm1.weight False\nblocks.4.norm1.bias False\nblocks.4.attn.qkv.weight False\nblocks.4.attn.qkv.bias False\nblocks.4.attn.proj.weight False\nblocks.4.attn.proj.bias False\nblocks.4.ls1.gamma False\nblocks.4.norm2.weight False\nblocks.4.norm2.bias False\nblocks.4.mlp.fc1.weight False\nblocks.4.mlp.fc1.bias False\nblocks.4.mlp.fc2.weight False\nblocks.4.mlp.fc2.bias False\nblocks.4.ls2.gamma False\nblocks.5.norm1.weight False\nblocks.5.norm1.bias False\nblocks.5.attn.qkv.weight False\nblocks.5.attn.qkv.bias False\nblocks.5.attn.proj.weight False\nblocks.5.attn.proj.bias False\nblocks.5.ls1.gamma False\nblocks.5.norm2.weight False\nblocks.5.norm2.bias False\nblocks.5.mlp.fc1.weight False\nblocks.5.mlp.fc1.bias False\nblocks.5.mlp.fc2.weight False\nblocks.5.mlp.fc2.bias False\nblocks.5.ls2.gamma False\nblocks.6.norm1.weight False\nblocks.6.norm1.bias False\nblocks.6.attn.qkv.weight False\nblocks.6.attn.qkv.bias False\nblocks.6.attn.proj.weight False\nblocks.6.attn.proj.bias False\nblocks.6.ls1.gamma False\nblocks.6.norm2.weight False\nblocks.6.norm2.bias False\nblocks.6.mlp.fc1.weight False\nblocks.6.mlp.fc1.bias False\nblocks.6.mlp.fc2.weight False\nblocks.6.mlp.fc2.bias False\nblocks.6.ls2.gamma False\nblocks.7.norm1.weight False\nblocks.7.norm1.bias False\nblocks.7.attn.qkv.weight False\nblocks.7.attn.qkv.bias False\nblocks.7.attn.proj.weight False\nblocks.7.attn.proj.bias False\nblocks.7.ls1.gamma False\nblocks.7.norm2.weight False\nblocks.7.norm2.bias False\nblocks.7.mlp.fc1.weight False\nblocks.7.mlp.fc1.bias False\nblocks.7.mlp.fc2.weight False\nblocks.7.mlp.fc2.bias False\nblocks.7.ls2.gamma False\nblocks.8.norm1.weight False\nblocks.8.norm1.bias False\nblocks.8.attn.qkv.weight False\nblocks.8.attn.qkv.bias False\nblocks.8.attn.proj.weight False\nblocks.8.attn.proj.bias False\nblocks.8.ls1.gamma False\nblocks.8.norm2.weight False\nblocks.8.norm2.bias False\nblocks.8.mlp.fc1.weight False\nblocks.8.mlp.fc1.bias False\nblocks.8.mlp.fc2.weight False\nblocks.8.mlp.fc2.bias False\nblocks.8.ls2.gamma False\nblocks.9.norm1.weight False\nblocks.9.norm1.bias False\nblocks.9.attn.qkv.weight False\nblocks.9.attn.qkv.bias False\nblocks.9.attn.proj.weight False\nblocks.9.attn.proj.bias False\nblocks.9.ls1.gamma False\nblocks.9.norm2.weight False\nblocks.9.norm2.bias False\nblocks.9.mlp.fc1.weight False\nblocks.9.mlp.fc1.bias False\nblocks.9.mlp.fc2.weight False\nblocks.9.mlp.fc2.bias False\nblocks.9.ls2.gamma False\nblocks.10.norm1.weight False\nblocks.10.norm1.bias False\nblocks.10.attn.qkv.weight False\nblocks.10.attn.qkv.bias False\nblocks.10.attn.proj.weight False\nblocks.10.attn.proj.bias False\nblocks.10.ls1.gamma False\nblocks.10.norm2.weight False\nblocks.10.norm2.bias False\nblocks.10.mlp.fc1.weight False\nblocks.10.mlp.fc1.bias False\nblocks.10.mlp.fc2.weight False\nblocks.10.mlp.fc2.bias False\nblocks.10.ls2.gamma False\nblocks.11.norm1.weight False\nblocks.11.norm1.bias False\nblocks.11.attn.qkv.weight False\nblocks.11.attn.qkv.bias False\nblocks.11.attn.proj.weight False\nblocks.11.attn.proj.bias False\nblocks.11.ls1.gamma False\nblocks.11.norm2.weight False\nblocks.11.norm2.bias False\nblocks.11.mlp.fc1.weight False\nblocks.11.mlp.fc1.bias False\nblocks.11.mlp.fc2.weight False\nblocks.11.mlp.fc2.bias False\nblocks.11.ls2.gamma False\nnorm.weight False\nnorm.bias False\nhead.0.weight True\nhead.0.bias True\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nconfig = LoraConfig(\n    r=16,\n    lora_alpha=16,\n    target_modules=[\"head.0\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n    modules_to_save=[\"classifier\"],\n)\nmodel = get_peft_model(model, config)\nmodel=model.to(device)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:57:55.923612Z","iopub.execute_input":"2024-05-25T17:57:55.924483Z","iopub.status.idle":"2024-05-25T17:58:07.819566Z","shell.execute_reply.started":"2024-05-25T17:57:55.924449Z","shell.execute_reply":"2024-05-25T17:58:07.818607Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"trainable params: 12,400 || all params: 86,597,495 || trainable%: 0.0143\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())\ntrain_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer,\n                                                                 10, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:58:22.458800Z","iopub.execute_input":"2024-05-25T17:58:22.459428Z","iopub.status.idle":"2024-05-25T20:42:43.674736Z","shell.execute_reply.started":"2024-05-25T17:58:22.459397Z","shell.execute_reply":"2024-05-25T20:42:43.673489Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Epoch 0\n train loss: 1.0202400043606759, train acc: 0.6488636363636363\n val loss: 0.8231396345382042, val acc: 0.7016576484162756\n\nEpoch 1\n train loss: 0.7373947593298825, train acc: 0.7289772727272728\n val loss: 0.7446067761233512, val acc: 0.7342030450384668\n\nEpoch 2\n train loss: 0.6250645535913381, train acc: 0.7713068181818182\n val loss: 0.636304590296238, val acc: 0.7634927547992544\n\nEpoch 3\n train loss: 0.5807541770013895, train acc: 0.7869318181818182\n val loss: 0.642707052065971, val acc: 0.7614636833363391\n\nEpoch 4\n train loss: 0.5488276739012111, train acc: 0.7988636363636363\n val loss: 0.5951205650542645, val acc: 0.7890911590545735\n\nEpoch 5\n train loss: 0.5355052097277208, train acc: 0.8039772727272727\n val loss: 0.5723114796775453, val acc: 0.7917507335226587\n\nEpoch 6\n train loss: 0.5165385353971611, train acc: 0.8085227272727272\n val loss: 0.5616588145494461, val acc: 0.7963705982299562\n\nEpoch 7\n train loss: 0.4954388031228022, train acc: 0.8167613636363636\n val loss: 0.5706416812348873, val acc: 0.7967374356503182\n\nEpoch 8\n train loss: 0.491641934893348, train acc: 0.8132102272727273\n val loss: 0.5813918754141382, val acc: 0.7887587122460629\n\nEpoch 9\n train loss: 0.4846635322679173, train acc: 0.8258522727272727\n val loss: 0.5541411387793561, val acc: 0.7977003854639987\n\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = []\ngt = []\n\nloss_log = []\nacc_log = []\nmodel.eval()\n    \nstartT = timeit.default_timer() \nfor data, target in val_loader:\n    data = data.to(device)\n    target = target.to(device)\n\n    with torch.no_grad():\n        predictions = model(data)\n        loss = nn.functional.cross_entropy(predictions, target)\n\n        loss_log.append(loss.item())\n\n        acc = sum(torch.argmax(predictions.cpu(), dim=1) ==\n                target.cpu()) / target.cpu().shape[0]\n\n        acc_log.append(acc.item())\n        \n        for i in range(len(target)):\n            preds.append(torch.argmax(predictions[i].cpu()))\n            gt.append(target[i].cpu())\n            \nendT = timeit.default_timer()\nrun_time = endT-startT","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:47:21.941173Z","iopub.execute_input":"2024-05-25T20:47:21.941554Z","iopub.status.idle":"2024-05-25T20:52:18.463283Z","shell.execute_reply.started":"2024-05-25T20:47:21.941524Z","shell.execute_reply":"2024-05-25T20:52:18.462156Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"print(classification_report(gt, preds))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:53:39.844485Z","iopub.execute_input":"2024-05-25T20:53:39.845185Z","iopub.status.idle":"2024-05-25T20:53:39.962960Z","shell.execute_reply.started":"2024-05-25T20:53:39.845150Z","shell.execute_reply":"2024-05-25T20:53:39.962017Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.48      0.12      0.19        93\n           1       0.76      0.65      0.70       164\n           2       0.49      0.73      0.59       315\n           3       0.65      0.30      0.41        44\n           4       0.59      0.36      0.44       338\n           5       0.89      0.94      0.91      2012\n           6       0.90      0.69      0.78        39\n\n    accuracy                           0.80      3005\n   macro avg       0.68      0.54      0.58      3005\nweighted avg       0.79      0.80      0.78      3005\n\n","output_type":"stream"}]}]}