{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc-autonumbering":true,"toc-showmarkdowntxt":true,"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8274525,"sourceType":"datasetVersion","datasetId":4913304},{"sourceId":42514,"sourceType":"modelInstanceVersion","modelInstanceId":35723}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm\n!pip install einops\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom PIL import Image\nfrom einops import rearrange\nimport torchvision\nfrom torch import nn, optim\nimport timm\nimport imageio.v2 as imageio\nfrom torchvision.transforms import v2\nfrom glob import glob\nfrom sklearn.preprocessing import LabelEncoder\nimport time\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\nfrom torch import linalg as LA\nimport prettytable\nimport time, random,timeit\nimport sys\nsys.setrecursionlimit(15000)\n\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom tqdm.notebook import tqdm\nimport seaborn as sns","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-05-11T19:48:59.940981Z","iopub.execute_input":"2024-05-11T19:48:59.942111Z","iopub.status.idle":"2024-05-11T19:49:33.187104Z","shell.execute_reply.started":"2024-05-11T19:48:59.942064Z","shell.execute_reply":"2024-05-11T19:49:33.185884Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2+cpu)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.22.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\nCollecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"normalize = transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\nResize = transforms.Resize((384,384))\n\npin_memory = True\nnw = 6 \n\ndata_transform = {\n        \"train\": transforms.Compose([Resize,\n                                     transforms.RandomVerticalFlip(),\n                                     transforms.ToTensor(),\n                                     normalize]),\n        \"val\": transforms.Compose([Resize,\n                                    transforms.ToTensor(),\n                                    normalize]),\n        \"test\": transforms.Compose([Resize,\n                                    transforms.ToTensor(),\n                                    normalize]),}    \n\ntrain_dataset = datasets.ImageFolder(root='/kaggle/input/ham10000-augmented/ham10000_augmented/train525e384',transform=data_transform[\"train\"])\nval_dataset = datasets.ImageFolder(root='/kaggle/input/ham10000-augmented/ham10000_augmented/val525e384png',transform=data_transform[\"val\"])\ntest_dataset = datasets.ImageFolder(root='/kaggle/input/ham10000-augmented/ham10000_augmented/test525png384',transform=data_transform[\"test\"])\n\ntrain_num = len(train_dataset)\nval_num = len(val_dataset)\ntest_num = len(test_dataset)\n\ntrain_loader = DataLoader(train_dataset,batch_size=168,\n                                                   pin_memory=pin_memory,\n                                                   shuffle=True,num_workers=nw)\nval_loader = DataLoader(val_dataset,batch_size=21,\n                                                   pin_memory=pin_memory,\n                                                   shuffle=True,num_workers=nw)\ntest_loader = DataLoader(test_dataset,batch_size=21,\n                                                  pin_memory=pin_memory,\n                                                  shuffle=False,num_workers=nw)\n\nprint(\"using {} images for training, {} images for val, {} images for testing.\".format(train_num,val_num,test_num))\n\n    \ndata_list = test_dataset.class_to_idx\ncla_dict = dict((val, key) for key, val in data_list.items())\nn_classes  = len(data_list)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-05-11T19:49:33.191491Z","iopub.execute_input":"2024-05-11T19:49:33.191891Z","iopub.status.idle":"2024-05-11T19:49:55.769319Z","shell.execute_reply.started":"2024-05-11T19:49:33.191859Z","shell.execute_reply":"2024-05-11T19:49:55.768126Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"using 51646 images for training, 1006 images for val, 828 images for testing.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset.class_to_idx","metadata":{"execution":{"iopub.status.busy":"2024-05-11T19:49:55.770631Z","iopub.execute_input":"2024-05-11T19:49:55.771067Z","iopub.status.idle":"2024-05-11T19:49:55.779115Z","shell.execute_reply.started":"2024-05-11T19:49:55.771001Z","shell.execute_reply":"2024-05-11T19:49:55.778190Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}"},"metadata":{}}]},{"cell_type":"code","source":"loc_time = time.strftime(\"%H%M%S\", time.localtime()) \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nratio = 8\n# c_outs= 128\nreduction = 1 # default:1\nn_iter = 0\n\ndef squash(inputs,ep_iter=n_iter,total=100):\n    beta = 1.45 - 0.22* (ep_iter/total)\n    mag_sq = torch.sum(inputs**2, dim=2, keepdim=True)\n    mag = torch.sqrt(mag_sq)\n    s = (mag_sq / (beta + mag_sq)) * (inputs / mag)\n    return s\n\n\nclass CapsNet(nn.Module):\n    def __init__(self,conv_inputs,\n                 num_classes=7,\n                 init_weights=False,\n                 conv_outputs = 128,\n                 primary_units = 8,#8,\n                 primary_unit_size = 576,# 16 * 6 * 6,\n                 output_unit_size = 16,):\n        super().__init__()\n        \n        self.Convolution = nn.Sequential(nn.Conv2d(conv_inputs, conv_outputs, 21,stride=2),\n                                        nn.BatchNorm2d(conv_outputs),\n                                        nn.ReLU(inplace=True),)\n\n        \n\n        # self.Pool = nn.FractionalMaxPool2d(3, output_size=(20))\n        self.Pool = nn.AdaptiveMaxPool2d(20)\n        #Attention\n        self.CBAM = Conv_CBAM(conv_outputs,conv_outputs)\n        #Capsule\n        self.primary = Primary_Caps(in_channels=conv_outputs,#128\n                                    caps_units=primary_units,#8\n                                    )\n\n        self.digits = Digits_Caps(in_units=primary_units,#8\n                                   in_channels=primary_unit_size,#16*6*6=576\n                                   num_units=num_classes,#classification_num\n                                   unit_size=output_unit_size,#16\n                                   )\n        if init_weights:\n            self._initialize_weights()\n        \n    def forward(self, x):\n        x = self.Convolution(x)\n        x = self.Pool(x)      \n        x = self.CBAM(x)\n        out = self.digits(self.primary(x))\n        return out\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):# or isinstance(m, nn.BatchNorm2d):\n                nn.init.normal_(m.weight, 0, 0.01)\n                # nn.init.constant_(m.bias, 0)\n    #margin_loss           \n    def loss(self,img_input, target, epoch=1,epoch_total=100, size_average=True):\n    # def loss(self,img_input, target, size_average=True):\n        batch_size = img_input.size(0)\n        # coefficient = epoch/epoch_total\n        \n        v_mag = LA.norm(img_input,ord=2,dim=(2,3),keepdim=True) #largest singular value\n        zero = Variable(torch.zeros(1)).to(device)\n        m_plus  = 0.9 #- (coefficient/10) \n        m_minus =0.1 #+ (coefficient/10)\n        max_l = torch.max(m_plus - v_mag, zero).view(batch_size, -1)**2\n        max_r = torch.max(v_mag - m_minus, zero).view(batch_size, -1)**2\n        \n        # init_lambda = 0.5 \n        loss_lambda = 0.5 #+ coefficient\n        # print(f\"lambda:{loss_lambda}\")\n        T_c = target\n        L_c = T_c * max_l + loss_lambda * (1.0 - T_c) * max_r\n        L_c = torch.sum(L_c,1)\n        \n        if size_average:\n            L_c = torch.mean(L_c)\n\n        return L_c\n\n    def update_n_iter(self, ep_iter):\n        if ep_iter > 100 and ep_iter % 10 == 0:\n            ep_iter -=100\n            self.primary.n_iter = ep_iter\n            self.digits.n_iter = ep_iter\n            beta = 1.45 - 0.22* (ep_iter/100)\n            print(f\"beta:{beta}\")\n        \n        \nclass Primary_Caps(nn.Module):\n    def __init__(self, in_channels, caps_units):\n        super(Primary_Caps, self).__init__()\n        self.n_iter = n_iter\n        self.in_channels = in_channels\n        self.caps_units = caps_units\n        \n        def create_conv_unit(unit_idx):\n            unit = ConvUnit(in_channels=in_channels)\n            self.add_module(\"Caps_\" + str(unit_idx), unit)\n            return unit\n        self.units = [create_conv_unit(i) for i in range(self.caps_units)]\n   \n    #no_routing\n    def forward(self, x):\n        # Get output for each unit.\n        # Each will be (batch, channels, height, width).\n        u = [self.units[i](x) for i in range(self.caps_units)]\n        # Stack all unit outputs (batch, unit, channels, height, width).\n        u = torch.stack(u, dim=1)\n        # Flatten to (batch, unit, output).\n        u = u.view(x.size(0), self.caps_units, -1)\n\n        return squash(u,self.n_iter)\n    \nclass Digits_Caps(nn.Module):\n    def __init__(self, in_units, in_channels, num_units, unit_size):\n        super(Digits_Caps, self).__init__()\n        self.n_iter = n_iter\n        self.in_units = in_units\n        self.in_channels = in_channels\n        self.num_units = num_units\n        \n        self.W = nn.Parameter(torch.randn(1, in_channels, self.num_units, unit_size, in_units))\n        # self.w = [1,576,7,16,8]\n        \n    #routing\n    def forward(self, x):\n        batch_size = x.size(0)    \n        # (batch, in_units, features) -> (batch, features, in_units)\n        x = x.transpose(1, 2)        \n        # (batch, features, in_units) -> (batch, features, num_units, in_units, 1)\n        x = torch.stack([x] * self.num_units, dim=2).unsqueeze(4)        \n        # (batch, features, in_units, unit_size, num_units)\n        W = torch.cat([self.W] * batch_size, dim=0)\n        # Transform inputs by weight matrix.\n        # (batch_size, features, num_units, unit_size, 1)\n        u_hat = torch.matmul(W, x)\n        # Initialize routing logits to zero.\n        b_ij = Variable(torch.zeros(1, self.in_channels, self.num_units, 1)).to(device)\n        \n        num_iterations = 3\n        for iteration in range(num_iterations):\n            # Convert routing logits to softmax.\n            # (batch, features, num_units, 1, 1)\n            #c_ij = F.softmax(b_ij, dim=0)\n            c_ij = b_ij.softmax(dim=1)\n            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n\n            # Apply routing (c_ij) to weighted inputs (u_hat).\n            # (batch_size, 1, num_units, unit_size, 1)\n            s_j = torch.sum(c_ij * u_hat, dim=1, keepdim=True)\n\n            # (batch_size, 1, num_units, unit_size, 1)\n            v_j = squash(s_j,self.n_iter)\n\n            # (batch_size, features, num_units, unit_size, 1)\n            v_j1 = torch.cat([v_j] * self.in_channels, dim=1)\n\n            # (batch_size, features, num_units, 1)\n            u_vj1 = torch.matmul(u_hat.transpose(3, 4), v_j1).squeeze(4).mean(dim=0, keepdim=True)\n\n            # Update b_ij (routing)\n            b_ij = u_vj1\n\n        # return v_j.squeeze(1)\n        return rearrange(v_j.squeeze(1), 'b c (g h) w -> b c g (h w)',g=4)\n                \nclass ConvUnit(nn.Module):\n    def __init__(self, in_channels):\n        super(ConvUnit, self).__init__()\n        Caps_out = in_channels // ratio# 16\n        self.Cpas = nn.Sequential(\n                        # nn.Conv2d(in_channels,Caps_out,(9,9),stride=2,groups=Caps_out, bias=False),\n                        nn.Conv2d(in_channels,in_channels,(9,1),stride=1, bias=False),\n                        nn.Conv2d(in_channels,Caps_out,(1,9),stride=2,groups=Caps_out, bias=False),\n                    )\n\n    def forward(self, x):\n        output = self.Cpas(x)\n        return output\n\nclass Conv_CBAM(nn.Module):\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):\n        super(Conv_CBAM, self).__init__()\n        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)\n        self.bn = nn.BatchNorm2d(c2)\n        self.act = nn.Hardswish() if act else nn.Identity()\n        self.ca = ChannelAttention(c2, reduction=reduction)\n        self.sa = SpatialAttention()\n\n    def forward(self, x):\n        x = self.act(self.bn(self.conv(x)))\n        x = self.ca(x) * x\n        x = self.sa(x) * x\n        return x\n    \ndef autopad(k, p=None):  # kernel, padding\n    if p is None:\n        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]\n    return p\n\n# SAM\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=3): # default:3\n        super(SpatialAttention, self).__init__()\n\n        assert kernel_size in (3, 7)\n        padding = 3 if kernel_size == 7 else 1\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size,padding=padding, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # This is different from the paper[S. Woo, et al. \"CBAM: Convolutional Block Attention Module,\"].\n        avg_out = torch.mean(x, dim=1, keepdim=True)#The different channels are averaged and converted to 1 channel.\n        max_out, _ = torch.max(x, dim=1, keepdim=True)#Maximizing the different channels and making them 1-channel.\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)\n\n# CAM\nclass ChannelAttention(nn.Module):\n    def __init__(self, channels, reduction=16):\n        super(ChannelAttention, self).__init__()\n        me_c = channels // reduction\n        self.avg_pool = nn.AdaptiveAvgPool2d(1) \n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n        self.fc1   = nn.Conv2d(channels, me_c, 1, bias=False)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.fc2   = nn.Conv2d(me_c, channels, 1, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n        out = avg_out + max_out\n        return self.sigmoid(out)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T19:49:55.781494Z","iopub.execute_input":"2024-05-11T19:49:55.781825Z","iopub.status.idle":"2024-05-11T19:49:55.820575Z","shell.execute_reply.started":"2024-05-11T19:49:55.781797Z","shell.execute_reply":"2024-05-11T19:49:55.819671Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"n_channels = 3 #RGB\n\nnetwork = CapsNet(conv_inputs=n_channels, \n                     num_classes=7,# category_number\n                     init_weights=True,)\nnetwork = network.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T19:49:55.821708Z","iopub.execute_input":"2024-05-11T19:49:55.822443Z","iopub.status.idle":"2024-05-11T19:49:55.923294Z","shell.execute_reply.started":"2024-05-11T19:49:55.822412Z","shell.execute_reply":"2024-05-11T19:49:55.922436Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"network.load_state_dict(torch.load('/kaggle/input/capsnet_78/pytorch/capsnet_78/1/gpu_78_epochs_capsnet.pth',\n                                  map_location=torch.device('cpu')))","metadata":{"execution":{"iopub.status.busy":"2024-05-11T19:49:55.924996Z","iopub.execute_input":"2024-05-11T19:49:55.925790Z","iopub.status.idle":"2024-05-11T19:49:56.051115Z","shell.execute_reply.started":"2024-05-11T19:49:55.925750Z","shell.execute_reply":"2024-05-11T19:49:56.050223Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nloss_log = []\nacc_log = []\nnetwork.eval()\n\npredictions = []\ngt = []\n\ndef one_hot(x, length):\n    batch_size = x.size(0)\n    x_one_hot = torch.zeros(batch_size, length)\n    for i in range(batch_size):\n        x_one_hot[i, x[i]] = 1.0\n    return x_one_hot\n\ncor_loss,correct,Auc, Acc= 0, 0, 0, 0\nevl_tmp_result = torch.zeros(n_classes,n_classes)\n    \n\ndata_loader = test_loader\ntmp_size = 21\ndata_num = test_num\n        \nsteps_num = len(data_loader)\n    \nwith torch.no_grad():\n    for batch_idx, (data, target) in enumerate(data_loader):\n        batch_idx +=1\n        target_indices = target#torch.Size([batch, 7])  \n        target_one_hot = one_hot(target, length=n_classes)            \n        data, target = Variable(data).to(device), Variable(target_one_hot).to(device)\n\n        output= network(data)#torch.Size([batch_size, 7, 16, 1])         \n        v_mag = LA.norm(output,ord='nuc',dim=(2,3), keepdim=True)#\n        pred = v_mag.data.max(1, keepdim=True)[1].cpu()#[9, 2, 1, 1, 6,..., 1, 4, 6, 5, 7,]\n            \n        if batch_idx % steps_num == 0 and data_num % tmp_size != 0:\n            tmp_size = data_num % tmp_size\n                          \n        for i in range(tmp_size):\n            pred_y = pred.numpy()\n            evl_tmp_result[target_indices[i]][pred_y[i]] +=1 \n            predictions.append(pred_y[i])\n            gt.append(target_indices[i])\n\n    diag_sum = torch.sum(evl_tmp_result.diagonal())\n    all_sum = torch.sum(evl_tmp_result) \n    test_acc = 100. * float(torch.div(diag_sum,all_sum)) ","metadata":{"execution":{"iopub.status.busy":"2024-05-11T19:49:56.053413Z","iopub.execute_input":"2024-05-11T19:49:56.054576Z","iopub.status.idle":"2024-05-11T19:51:31.332253Z","shell.execute_reply.started":"2024-05-11T19:49:56.054533Z","shell.execute_reply":"2024-05-11T19:51:31.330760Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}]},{"cell_type":"code","source":"test_acc","metadata":{"execution":{"iopub.status.busy":"2024-05-11T19:51:31.333813Z","iopub.execute_input":"2024-05-11T19:51:31.334185Z","iopub.status.idle":"2024-05-11T19:51:31.341565Z","shell.execute_reply.started":"2024-05-11T19:51:31.334133Z","shell.execute_reply":"2024-05-11T19:51:31.340372Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"92.87439584732056"},"metadata":{}}]},{"cell_type":"code","source":"def test(model, loader):\n    loss_log = []\n    acc_log = []\n    model.eval()\n    \n    startT = timeit.default_timer() \n    for data, target in loader:\n        data = data.to(device)\n        target = target.to(device)\n\n        with torch.no_grad():\n            predictions = model(data)\n            loss = nn.functional.cross_entropy(predictions, target)\n\n            loss_log.append(loss.item())\n\n            acc = sum(torch.argmax(predictions.cpu(), dim=1) ==\n                   target.cpu()) / target.cpu().shape[0]\n\n            acc_log.append(acc.item())\n            \n    endT = timeit.default_timer()\n    run_time = endT-startT\n\n    return np.mean(loss_log), np.mean(acc_log), run_time\n\ndef train_epoch(model, optimizer, train_loader):\n    loss_log = []\n    acc_log = []\n    model.train()\n\n    for data, target in train_loader:\n        data = data.to(device)\n        target = target.to(device)\n\n        optimizer.zero_grad()\n        predictions = model(data)\n        loss = nn.functional.cross_entropy(predictions, target)\n        loss.backward()\n        optimizer.step()\n\n        loss_log.append(loss.item())\n\n        with torch.no_grad():\n            acc = sum(torch.argmax(predictions.cpu(), dim=1) ==\n                   target.cpu()) / target.cpu().shape[0]\n\n        acc_log.append(acc.item())\n\n    return loss_log, acc_log\n\ndef train(model, optimizer, n_epochs, train_loader, val_loader, scheduler=None):\n    train_loss_log, train_acc_log, val_loss_log, val_acc_log = [], [], [], []\n    \n\n    for epoch in range(n_epochs):\n        startT = timeit.default_timer() \n        train_loss, train_acc = train_epoch(model, optimizer, train_loader)\n        val_loss, val_acc = test(model, val_loader)\n\n        train_loss_log.extend(train_loss)\n        train_acc_log.extend(train_acc)\n\n        val_loss_log.append(val_loss)\n        val_acc_log.append(val_acc)\n\n        print(f\"Epoch {epoch}\")\n        print(f\" train loss: {np.mean(train_loss)}, train acc: {np.mean(train_acc)}\")\n        print(f\" val loss: {val_loss}, val acc: {val_acc}\\n\")\n        endT = timeit.default_timer()\n        run_time = endT-startT\n        print(\"Running:[{:.2f}s]\".format(run_time))\n\n        if scheduler is not None:\n            scheduler.step(val_acc)\n            \n    return train_loss_log, train_acc_log, val_loss_log, val_acc_log","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:04:30.635790Z","iopub.execute_input":"2024-05-03T06:04:30.636271Z","iopub.status.idle":"2024-05-03T06:04:30.657680Z","shell.execute_reply.started":"2024-05-03T06:04:30.636229Z","shell.execute_reply":"2024-05-03T06:04:30.656651Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"normalize = transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\nResize = transforms.Resize((384,384))\n\npin_memory = True\nnw = 2\n\ndata_transform = {\n        \"train\": transforms.Compose([Resize,\n                                     transforms.RandomVerticalFlip(),\n                                     transforms.ToTensor(),\n                                     normalize]),\n        \"val\": transforms.Compose([Resize,\n                                    transforms.ToTensor(),\n                                    normalize]),\n        \"test\": transforms.Compose([Resize,\n                                    transforms.ToTensor(),\n                                    normalize]),}    \n\ntrain_dataset = datasets.ImageFolder(root='/kaggle/input/ham10000-augmented/ham10000_augmented/train525e384',transform=data_transform[\"train\"])\nval_dataset = datasets.ImageFolder(root='/kaggle/input/ham10000-augmented/ham10000_augmented/val525e384png',transform=data_transform[\"val\"])\ntest_dataset = datasets.ImageFolder(root='/kaggle/input/ham10000-augmented/ham10000_augmented/test525png384',transform=data_transform[\"test\"])\n\ntrain_num = len(train_dataset)\nval_num = len(val_dataset)\ntest_num = len(test_dataset)\n\ntrain_loader = DataLoader(train_dataset,batch_size=32,\n                                                   pin_memory=pin_memory,\n                                                   shuffle=True,num_workers=nw)\nval_loader = DataLoader(val_dataset,batch_size=21,\n                                                   pin_memory=pin_memory,\n                                                   shuffle=True,num_workers=nw)\ntest_loader = DataLoader(test_dataset,batch_size=21,\n                                                  pin_memory=pin_memory,\n                                                  shuffle=False,num_workers=nw)\n\nprint(\"using {} images for training, {} images for val, {} images for testing.\".format(train_num,val_num,test_num))\n\n    \ndata_list = test_dataset.class_to_idx\ncla_dict = dict((val, key) for key, val in data_list.items())\nn_classes  = len(data_list)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T20:10:49.347255Z","iopub.execute_input":"2024-05-02T20:10:49.347627Z","iopub.status.idle":"2024-05-02T20:11:15.009907Z","shell.execute_reply.started":"2024-05-02T20:10:49.347592Z","shell.execute_reply":"2024-05-02T20:11:15.009022Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"using 51646 images for training, 1006 images for val, 828 images for testing.\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = timm.create_model('resnet50', pretrained=True)\nnum_classes = 7\n\nnum_features = model.fc.in_features\n\nmodel.fc = nn.Sequential(\n    nn.Linear(num_features, num_classes)\n)\nmodel=model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T20:11:15.011807Z","iopub.execute_input":"2024-05-02T20:11:15.012099Z","iopub.status.idle":"2024-05-02T20:11:16.870757Z","shell.execute_reply.started":"2024-05-02T20:11:15.012073Z","shell.execute_reply":"2024-05-02T20:11:16.869727Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0531c5bd4014e9caadc30e71d4d66ad"}},"metadata":{}}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())\ntrain_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer,\n                                                                 75, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T20:11:16.871931Z","iopub.execute_input":"2024-05-02T20:11:16.872221Z","iopub.status.idle":"2024-05-03T06:01:15.298217Z","shell.execute_reply.started":"2024-05-02T20:11:16.872195Z","shell.execute_reply":"2024-05-03T06:01:15.296896Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 0\n train loss: 0.5104344496007228, train acc: 0.8104812061181004\n val loss: 0.5999024718378981, val acc: 0.7985066957771778\n\nRunning:[1360.48s]\nEpoch 1\n train loss: 0.21462272100215213, train acc: 0.9224726352771419\n val loss: 0.6361353615454087, val acc: 0.8142752821246783\n\nRunning:[1364.45s]\nEpoch 2\n train loss: 0.14696658857206005, train acc: 0.9468711276332095\n val loss: 0.3834760145594676, val acc: 0.875887643545866\n\nRunning:[1364.21s]\nEpoch 3\n train loss: 0.11544180848021776, train acc: 0.9599584365792139\n val loss: 0.46482765146841604, val acc: 0.8599102000395457\n\nRunning:[1363.66s]\nEpoch 4\n train loss: 0.0947139889007328, train acc: 0.966775092936803\n val loss: 0.41851218417286873, val acc: 0.8698308343688647\n\nRunning:[1362.41s]\nEpoch 5\n train loss: 0.07447148946772705, train acc: 0.9742061647931587\n val loss: 0.5148439831100404, val acc: 0.8598057727018992\n\nRunning:[1361.72s]\nEpoch 6\n train loss: 0.06946307160794075, train acc: 0.9763772717712832\n val loss: 0.41871339560020715, val acc: 0.8894632483522097\n\nRunning:[1360.94s]\nEpoch 7\n train loss: 0.05890386327796776, train acc: 0.9805413568773235\n val loss: 0.4418796340469271, val acc: 0.875887643545866\n\nRunning:[1362.45s]\nEpoch 8\n train loss: 0.05510272251493575, train acc: 0.9811222118959108\n val loss: 0.5472796099784318, val acc: 0.8624686797459921\n\nRunning:[1363.04s]\nEpoch 9\n train loss: 0.04583311501818364, train acc: 0.9845286038654593\n val loss: 0.6437027958357552, val acc: 0.861789899567763\n\nRunning:[1363.82s]\nEpoch 10\n train loss: 0.04070364162213699, train acc: 0.9863886307311028\n val loss: 0.5028913879456619, val acc: 0.871710533897082\n\nRunning:[1360.90s]\nEpoch 11\n train loss: 0.04194549830169196, train acc: 0.9864067017588917\n val loss: 0.5496374689197788, val acc: 0.8797514686981837\n\nRunning:[1361.03s]\nEpoch 12\n train loss: 0.03648301901415262, train acc: 0.9877426683016426\n val loss: 0.6293900097953156, val acc: 0.8590225651860237\n\nRunning:[1361.29s]\nEpoch 13\n train loss: 0.03039914442345298, train acc: 0.9896220570012392\n val loss: 0.5540491676874808, val acc: 0.8735902334252993\n\nRunning:[1361.53s]\nEpoch 14\n train loss: 0.03538416859196968, train acc: 0.98832352332023\n val loss: 0.578727321466431, val acc: 0.871031753718853\n\nRunning:[1361.03s]\nEpoch 15\n train loss: 0.03112114957293625, train acc: 0.9893109768518284\n val loss: 0.5147136708643908, val acc: 0.8798558972775936\n\nRunning:[1360.24s]\nEpoch 16\n train loss: 0.02743804268018049, train acc: 0.9909954564057318\n val loss: 0.5623973268472279, val acc: 0.8648705172042052\n\nRunning:[1360.55s]\nEpoch 17\n train loss: 0.025226393598172407, train acc: 0.9913646220570013\n val loss: 0.5485344290112456, val acc: 0.8793337581058344\n\nRunning:[1360.73s]\nEpoch 18\n train loss: 0.026927966548136877, train acc: 0.9910161090458488\n val loss: 0.5762108654113641, val acc: 0.8829365149140358\n\nRunning:[1359.68s]\nEpoch 19\n train loss: 0.027222116333719928, train acc: 0.9908805762081785\n val loss: 0.5340977379819378, val acc: 0.880952388048172\n\nRunning:[1359.48s]\nEpoch 20\n train loss: 0.01858625005377446, train acc: 0.994055916976456\n val loss: 0.5609624842776005, val acc: 0.885808277875185\n\nRunning:[1360.31s]\nEpoch 21\n train loss: 0.024023764435239084, train acc: 0.9921197335811648\n val loss: 0.6003878960036673, val acc: 0.8797514686981837\n\nRunning:[1362.11s]\nEpoch 22\n train loss: 0.020918852354808577, train acc: 0.9932814436183395\n val loss: 0.5171318886059453, val acc: 0.8947368487715721\n\nRunning:[1361.18s]\nEpoch 23\n train loss: 0.0214385033418981, train acc: 0.9930103779429987\n val loss: 0.45365756635631743, val acc: 0.8925438659886519\n\nRunning:[1361.65s]\nEpoch 24\n train loss: 0.017838665685085492, train acc: 0.994055916976456\n val loss: 0.6325329635462064, val acc: 0.8795426140228907\n\nRunning:[1362.38s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[0;32m----> 2\u001b[0m train_loss_log, train_acc_log, val_loss_log, val_acc_log \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[2], line 55\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, n_epochs, train_loader, val_loader, scheduler)\u001b[0m\n\u001b[1;32m     53\u001b[0m startT \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer() \n\u001b[1;32m     54\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_epoch(model, optimizer, train_loader)\n\u001b[0;32m---> 55\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m train_loss_log\u001b[38;5;241m.\u001b[39mextend(train_loss)\n\u001b[1;32m     58\u001b[0m train_acc_log\u001b[38;5;241m.\u001b[39mextend(train_acc)\n","Cell \u001b[0;32mIn[2], line 14\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(predictions, target)\n\u001b[0;32m---> 14\u001b[0m loss_log\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(torch\u001b[38;5;241m.\u001b[39margmax(predictions\u001b[38;5;241m.\u001b[39mcpu(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m\n\u001b[1;32m     17\u001b[0m        target\u001b[38;5;241m.\u001b[39mcpu()) \u001b[38;5;241m/\u001b[39m target\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m acc_log\u001b[38;5;241m.\u001b[39mappend(acc\u001b[38;5;241m.\u001b[39mitem())\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"test(model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:04:35.134420Z","iopub.execute_input":"2024-05-03T06:04:35.134791Z","iopub.status.idle":"2024-05-03T06:04:42.076549Z","shell.execute_reply.started":"2024-05-03T06:04:35.134761Z","shell.execute_reply":"2024-05-03T06:04:42.075410Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(0.6289158628156656, 0.8904761958867311, 6.933684934003395)"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'gpu_75_epochs_resnet.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:10:15.453264Z","iopub.execute_input":"2024-05-03T06:10:15.454157Z","iopub.status.idle":"2024-05-03T06:10:15.695715Z","shell.execute_reply.started":"2024-05-03T06:10:15.454124Z","shell.execute_reply":"2024-05-03T06:10:15.694706Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-02T19:55:29.189771Z","iopub.execute_input":"2024-05-02T19:55:29.190160Z","iopub.status.idle":"2024-05-02T19:55:29.195008Z","shell.execute_reply.started":"2024-05-02T19:55:29.190125Z","shell.execute_reply":"2024-05-02T19:55:29.193801Z"},"trusted":true},"execution_count":7,"outputs":[]}]}